{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89659207",
   "metadata": {},
   "source": [
    "![bse_logo_textminingcourse](https://bse.eu/sites/default/files/bse_logo_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625f718",
   "metadata": {},
   "source": [
    "# Text Mining: Models and Algorithms\n",
    "\n",
    "## Problem Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10b564",
   "metadata": {},
   "source": [
    "### *1.⁠ ⁠Identify a (future) event that makes a lot of people come to Barcelona. Think about music festivals, local festivities etc. (2 points)*\n",
    "We have selected the Sónar festival. It is the 31st edition of the Barcelona International Festival of Advanced Music and Multimedia Art in 2024. This vibrant event takes place in Montjuic and attracts enthusiasts from all over the world to Barcelona to participate in its rich offer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd0077",
   "metadata": {},
   "source": [
    "### *2.⁠ ⁠Think of the time periods to scrape and what second city to scrape for these same timer periods. Explain your choices in written. (2 points)*\n",
    "\n",
    "The festival unfolds on June 13, 14, and 15, and we have opted to analyze the period preceding it, that is the corresponding days on June 6, 7, and 8, 2024. Ensuring an equivalent number of days and proximity to the event dates is crucial for a meaningful comparison of similar scenarios. We also include Valencia as the second city to control for due to its proximity and similarities to Barcelona. Both cities are located on Spain's eastern coastline along the Mediterranean Sea and share similar geographical and cultural situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "7259e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pandas\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
    "\n",
    "\n",
    "# Go get geckodriver from : https://github.com/mozilla/geckodriver/releases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d073a3b0",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffx_preferences(dfolder, download=False):\n",
    "    '''\n",
    "    Sets the preferences of the firefox browser: download path.\n",
    "    '''\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    # set download folder:\n",
    "    profile.set_preference(\"browser.download.dir\", dfolder)\n",
    "    profile.set_preference(\"browser.download.folderList\", 2)\n",
    "    profile.set_preference(\"browser.download.manager.showWhenStarting\", False)\n",
    "    profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\",\n",
    "                           \"application/msword,application/rtf, application/csv,text/csv,image/png ,image/jpeg, application/pdf, text/html,text/plain,application/octet-stream\")\n",
    "    \n",
    "    # profile.add_extension('/Users/luisignaciomenendezgarcia/Dropbox/CLASSES/class_bse_text_mining/class_scraping_bse/booking/booking/ublock_origin-1.55.0.xpi')\n",
    "\n",
    "\n",
    "    # this allows to download pdfs automatically\n",
    "    if download:\n",
    "        profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/pdf,application/x-pdf\")\n",
    "        profile.set_preference(\"pdfjs.disabled\", True)\n",
    "\n",
    "    options = Options()\n",
    "    options.profile = profile\n",
    "    return options\n",
    "\n",
    "\n",
    "def start_up(link, dfolder, geko_path,donwload=True):\n",
    "    # geko_path='/Users/luisignaciomenendezgarcia/Dropbox/CLASSES/class_bse_text_mining/class_scraping_bse/booking/geckodriver'\n",
    "    # download_path='./downloads'\n",
    "    os.makedirs(dfolder, exist_ok=True)\n",
    "\n",
    "    options = ffx_preferences(dfolder,donwload)\n",
    "    service = Service(geko_path)\n",
    "    browser = webdriver.Firefox(service=service, options=options)\n",
    "    # Enter the website address here\n",
    "    browser.get(link)\n",
    "    time.sleep(5)  # Adjust sleep time as needed\n",
    "    return browser\n",
    "        \n",
    "def check_and_click(browser, xpath, type):\n",
    "    '''\n",
    "    Function that checks whether the object is clickable and, if so, clicks on\n",
    "    it. If not, waits one second and tries again.\n",
    "    '''\n",
    "    start_time = time.time()  # Record the start time\n",
    "    while True:\n",
    "        try:\n",
    "            element = browser.find_element(By.XPATH, xpath)\n",
    "            element.click()\n",
    "            return \"Clicked!\"  # Element found and clicked successfully\n",
    "        except NoSuchElementException:\n",
    "            pass  # Continue if element not found\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return False  # Other unexpected errors\n",
    "\n",
    "        time.sleep(1)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time >= 3:\n",
    "            # print(\"** The element was not found in the page. **\")\n",
    "            return None  # Element not found after 5 seconds\n",
    "        \n",
    "def check_obscures(browser, xpath, type):\n",
    "    '''\n",
    "    Function that checks whether the object is being \"obscured\" by any element so\n",
    "    that it is not clickable. Important: if True, the object is going to be clicked!\n",
    "    '''\n",
    "    try:\n",
    "        if type == \"xpath\":\n",
    "            browser.find_element('xpath', xpath).click()\n",
    "        elif type == \"id\":\n",
    "            browser.find_element('id', xpath).click()\n",
    "        elif type == \"css\":\n",
    "            browser.find_element('css selector', xpath).click()\n",
    "        elif type == \"class\":\n",
    "            browser.find_element('class name', xpath).click()\n",
    "        elif type == \"link\":\n",
    "            browser.find_element('link text', xpath).click()\n",
    "    except (ElementClickInterceptedException, StaleElementReferenceException) as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    except NoSuchElementException:\n",
    "        # Do nothing if NoSuchElementException occurs (suppress the error)\n",
    "        pass\n",
    "    return True\n",
    "\n",
    "def element_exists(browser, path):\n",
    "    try:\n",
    "        browser.find_element('xpath', path)\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6174d6",
   "metadata": {},
   "source": [
    "### Scraping Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "3ca11b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scrape:\n",
    "    def __init__(self):\n",
    "        # print(\"Initializing the browser...\")\n",
    "        # time.sleep(1)\n",
    "        print(\"Remember to close the annoying Google popup on the page\")\n",
    "        dfolder='./downloads'\n",
    "        geko_path='./geckodriver'\n",
    "        link='https://www.booking.com/index.es.html'\n",
    "        self.browser =start_up(dfolder=dfolder,link=link,geko_path=geko_path)\n",
    "        self.search_bar_xpath = '//div[@class=\"b9b84f4305\"]'\n",
    "        self.search_x_path= '/html/body/div[3]/div[2]/div/form/div[1]/div[4]/button/span'\n",
    "        self.search_x_path2 = '/html/body/div[4]/div/div[2]/div/div[1]/div/form/div[1]/div[4]/button'\n",
    "        self.date_button_css = 'button.ebbedaf8ac:nth-child(2) > span:nth-child(1)'\n",
    "        self.number_of_people_xpath = '/html/body/div[3]/div[2]/div/form/div[1]/div[3]/div/button'\n",
    "        self.search_button_xpath = '/html/body/div[3]/div[2]/div/form/div[1]/div[4]/button/span'\n",
    "        self.x_path_prev_date = '//button[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 f671049264 deab83296e f4552b6561 dc72a8413c c9804790f7\"]'\n",
    "        self.x_path_next_date = '//button[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 f671049264 deab83296e f4552b6561 dc72a8413c f073249358\"]'\n",
    "        self.x_path_month = '//h3[@class=\"e1eebb6a1e ee7ec6b631\"]'\n",
    "        x_path_cookies = '//button[@id=\"onetrust-accept-btn-handler\"]'\n",
    "        self.people_path = '/html/body/div[3]/div[2]/div/form/div[1]/div[3]/div/button'\n",
    "        self.pages = 1\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36'}\n",
    "        self.data = pd.DataFrame(columns=['Hotels', 'Ratings', 'Price', 'Link'])\n",
    "        self.place = ''\n",
    "        check_and_click(self.browser, x_path_cookies, 'xpath')\n",
    "    def input_place(self):\n",
    "        place = input('Where do you want to go?')\n",
    "        self.place = (place.lower()).capitalize()\n",
    "        self.browser.find_element(by='xpath', value='//div[@class=\"b9b84f4305\"]').click()\n",
    "        search = self.browser.find_element(by='xpath', value='//*[@id=\":re:\"]')\n",
    "        search.clear()\n",
    "        search.send_keys(place)\n",
    "        print(f'Place of stay: {(place.lower()).capitalize()}')\n",
    "        x_path_close = '/html/body/div[4]/div/div[2]/div/div[1]/div/form/div[1]/div[1]/div/div/div[1]/div/div/div[1]/span/svg'\n",
    "        check_and_click(self.browser, x_path_close, 'xpath')\n",
    "    def input_dates(self):\n",
    "        print(\"Just a second...\")\n",
    "        self.browser.find_element('css selector',self.date_button_css).click()\n",
    "        while element_exists(self.browser, self.x_path_prev_date):\n",
    "                self.browser.find_element('xpath', self.x_path_prev_date).click()\n",
    "                time.sleep(1)\n",
    "        # Input the wanted year for the stay\n",
    "        start_date = (input(\"Input the start date of your programmed stay in the form (XX mes XXXX). Use Spanish month names. ¡Cuidado con la ortografía!\")).lower()\n",
    "        end_date = (input(\"Input the end date of your programmed stay in the form (XX mes XXXX). Use Spanish month names. ¡Cuidado con la ortografía!\")).lower()\n",
    "        # Retrieve the current date\n",
    "        month_and_year_start = start_date[3:]\n",
    "        month_and_year_end = end_date[3:]\n",
    "        month_and_year = self.browser.find_element('xpath', self.x_path_month).text\n",
    "        while month_and_year != month_and_year_start:\n",
    "                self.browser.find_element('xpath', self.x_path_next_date).click()\n",
    "                month_and_year = self.browser.find_element('xpath', self.x_path_month).text\n",
    "                time.sleep(1)\n",
    "        months_dict = {'enero': '01', 'febrero': '02', 'marzo': '03', 'abril': '04', 'mayo': '05', 'junio': '06', 'julio': '07', 'agosto': '08', 'septiembre': '09', 'octubre': '10', 'noviembre': '11', 'diciembre': '12'}\n",
    "        x_path_dates='//div[@id=\"calendar-searchboxdatepicker\"]//table[@class=\"eb03f3f27f\"]//tbody//td[@class=\"b80d5adb18\"]//span[@class=\"cf06f772fa\"]'\n",
    "        dates = self.browser.find_elements('xpath',x_path_dates)\n",
    "        from_day = start_date[:2]\n",
    "        to_day = end_date[:2]\n",
    "        month_start = month_and_year_start[:-5]\n",
    "        month_end = month_and_year_end[:-5]\n",
    "        year = month_and_year[-4:]\n",
    "        for date in dates:\n",
    "            if date.get_attribute(\"data-date\") == f\"{year}-{months_dict[month_start]}-{from_day}\":\n",
    "                date.click()\n",
    "                break\n",
    "        if month_start == month_end:\n",
    "            for date in dates:\n",
    "                if date.get_attribute(\"data-date\") == f\"{year}-{months_dict[month_end]}-{to_day}\":\n",
    "                    date.click()\n",
    "                    break\n",
    "        else:\n",
    "            while self.browser.find_element('xpath', self.x_path_month).text != month_and_year_end:\n",
    "                self.browser.find_element('xpath', self.x_path_next_date).click()\n",
    "            dates = self.browser.find_elements('xpath',x_path_dates)\n",
    "            for date in dates:\n",
    "                if date.get_attribute(\"data-date\") == f\"{year}-{months_dict[month_end]}-{to_day}\":\n",
    "                    date.click()\n",
    "                    break\n",
    "        self.browser.find_element('css selector',self.date_button_css).click()\n",
    "        print(f'Start date of the stay: {start_date}')\n",
    "        print(f'End date of the stay: {end_date}')\n",
    "    def input_people(self):\n",
    "        self.browser.find_element('xpath', self.people_path).click()\n",
    "        number_of_people = int(input('How many people in total are you looking an accomodation for?'))\n",
    "        css_minus = '/html/body/div[3]/div[2]/div/form/div[1]/div[3]/div/div/div/div/div[1]/div[2]/button[1]'\n",
    "        css_plus = '/html/body/div[3]/div[2]/div/form/div[1]/div[3]/div/div/div/div/div[1]/div[2]/button[2]'\n",
    "        if number_of_people == 1:\n",
    "            self.browser.find_element('xpath', css_minus).click()\n",
    "        elif number_of_people > 2:\n",
    "            i = 2\n",
    "            while i < number_of_people:\n",
    "                self.browser.find_element('xpath', css_plus).click()\n",
    "                i+=1\n",
    "                time.sleep(2)\n",
    "        self.browser.find_element('xpath', self.people_path).click()\n",
    "        print(f'Accomodations for: {number_of_people} people')\n",
    "    def search(self):\n",
    "        check_and_click(self.browser, self.search_x_path, 'xpath')\n",
    "        check_and_click(self.browser, self.search_x_path2, 'xpath')\n",
    "        place = self.place\n",
    "        print(f'Searching accomodations in {(place.lower()).capitalize()}...')\n",
    "        # self.browser.find_element('xpath', self.search_x_path).click()\n",
    "    def get_pages(self, limit=None):\n",
    "        a = self.browser.find_elements('xpath', '//button[@class=\"a83ed08757 a2028338ea\"]')\n",
    "        if a:\n",
    "            total_pages = int(a[-1].text)\n",
    "            if limit is not None and total_pages > limit:\n",
    "                self.pages = limit\n",
    "            else:\n",
    "                self.pages = total_pages\n",
    "        else:\n",
    "            self.pages = 1\n",
    "    def scrape_info(self):\n",
    "        print(\"Scraping general info...\\n\")\n",
    "        # Finding the button to change the page in Booking.com\n",
    "        change_page_xpath = '/html/body/div[4]/div/div[2]/div/div[2]/div[3]/div[2]/div[2]/div[4]/div[2]/nav/nav/div/div[3]/button/span/span'\n",
    "        css = 'div.b16a89683f:nth-child(3) > button:nth-child(1) > span:nth-child(1) > span:nth-child(1)'\n",
    "        # Make sure to be on the first page when starting to scrape the data\n",
    "        first_page_xpath='/html/body/div[4]/div/div[2]/div/div[2]/div[3]/div[2]/div[2]/div[4]/div[2]/nav/nav/div/div[2]/ol/li[1]/button'\n",
    "        check_and_click(self.browser,first_page_xpath , type='xpath')\n",
    "        # loop to scrape the data and populate the DataFrame\n",
    "        for i in range(self.pages):\n",
    "            print(f'Page: {i + 1}')\n",
    "            # Dividing the page in the Container Objects, one for every hotel\n",
    "            containers = self.browser.find_elements('xpath', '//div[@class=\"c066246e13\"]')\n",
    "            for hotel in containers:\n",
    "                hotel_name = hotel.find_element('xpath', './/div[@class=\"f6431b446c a15b38c233\"]').text\n",
    "                try:\n",
    "                    hotel_rating = hotel.find_element('xpath', './/div[@class=\"a3b8729ab1 d86cee9b25\"]').text\n",
    "                except:\n",
    "                    hotel_rating = np.nan\n",
    "                try:\n",
    "                    hotel_price = hotel.find_element('xpath', './/span[@class=\"f6431b446c fbfd7c1165 e84eb96b1f\"]').text\n",
    "                except:\n",
    "                    hotel_price = np.nan\n",
    "                try:\n",
    "                    url = hotel.find_element('xpath', './/a[@href]')\n",
    "                    hotel_url= url.get_attribute('href')\n",
    "                except:\n",
    "                    hotel_url = np.nan\n",
    "                new_row = {'Hotels': hotel_name, 'Ratings': hotel_rating, 'Price':hotel_price, 'Link': hotel_url}\n",
    "                # new_row = {'Hotels': hotel_name, 'Ratings': hotel_rating, 'Price':hotel_price, 'Link': hotel_url, 'Descriptions': hotel_description}\n",
    "                self.data = pd.concat([self.data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            # Change page with CSS Selector\n",
    "            next = self.browser.find_element('css selector', css)\n",
    "            time.sleep(2)\n",
    "        print(\"\\nDone!\\n\")\n",
    "        # display(self.data)\n",
    "    def scrape_description(self,url):\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            response.raise_for_status() \n",
    "            # time.sleep(0.5)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error processing {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        description_tag = soup.find('p', class_='a53cbfa6de b3efd73f69')\n",
    "\n",
    "        if description_tag:\n",
    "            return description_tag.get_text(strip=True)\n",
    "        else:\n",
    "            print(f\"Description tag not found on the page: {url}\")\n",
    "            return None\n",
    "    def get_descriptions(self):\n",
    "        print(\"Scraping descriptions...\")\n",
    "        # Set the number of concurrent threads (adjust this based on the processing power of your computer)\n",
    "        num_threads = 16\n",
    "        # Create a ThreadPoolExecutor to run operations in parallel\n",
    "        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            # Use executor.map to apply the scrape_description function to each URL in parallel\n",
    "            descriptions = []\n",
    "            for i, description in enumerate(executor.map(self.scrape_description, self.data['Link']), start=1):\n",
    "                descriptions.append(description)\n",
    "                # Print every 50 link to check the progess of the scraping\n",
    "                if i % 50 == 0:\n",
    "                    print(f\"Scraped {i} links\")\n",
    "        # Assign the descriptions to the 'Descriptions' column in the DataFrame\n",
    "        self.data['Descriptions'] = descriptions\n",
    "        # Print count after all threads have completed\n",
    "        print(f\"Scraped {len(descriptions)} links in total\")\n",
    "        display(self.data)\n",
    "        print(\"\\nDone!\\n\")\n",
    "        return (self.data)\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd2606",
   "metadata": {},
   "source": [
    "### *3. Design a careful scraping pipeline that follows the advises seen in class and TAs. (5points) The basic points to bear in mind are:*\n",
    "\n",
    "+ *Organize the data you need, format and structure to store it beforehand. Try to foresee how you will need to read in the data to answer your questions. If you want, you can include some few lines explaining your pipeline strategy at the*\n",
    "+ *Codes should be as automated as possible. That is, you don't want to rely on human intervention to get your data.*\n",
    "\n",
    "+ *Use only the packages we have seen in the course. Although firefox is recommended, you can also use chrome as your scraping browser.*\n",
    "\n",
    "+ *Document your codes and make them robust and efficient.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ed575",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "#### 1. Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "5f868e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instance1 = Scrape()\\ninstance1.input_place()\\ninstance1.input_dates()\\ninstance1.input_people()\\ninstance1.search()'"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"instance1 = Scrape()\n",
    "instance1.input_place()\n",
    "instance1.input_dates()\n",
    "instance1.input_people()\n",
    "instance1.search()\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816d6ab",
   "metadata": {},
   "source": [
    "#### Scraping general Information and Description text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "06e05322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instance1.get_pages(limit = 2)\\ninstance1.scrape_info()\\ndata = instance1.get_descriptions()'"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"instance1.get_pages(limit = 2)\n",
    "instance1.scrape_info()\n",
    "data = instance1.get_descriptions()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88349c",
   "metadata": {},
   "source": [
    "### *3. Design a careful scraping pipeline that follows the advises seen in class and TAs. (5points) The basic points to bear in mind are:*\n",
    "\n",
    "+ *Organize the data you need, format and structure to store it beforehand. Try to foresee how you will need to read in the data to answer your questions. If you want, you can include some few lines explaining your pipeline strategy at the*\n",
    "+ *Codes should be as automated as possible. That is, you don't want to rely on human intervention to get your data.*\n",
    "\n",
    "+ *Use only the packages we have seen in the course. Although firefox is recommended, you can also use chrome as your scraping browser.*\n",
    "\n",
    "+ *Document your codes and make them robust and efficient.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c8b44",
   "metadata": {},
   "source": [
    "## Pipeline (Step by Step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdc516",
   "metadata": {},
   "source": [
    "### 1. Opening the Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "b78b1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfolder='./downloads'\n",
    "geko_path='./geckodriver'\n",
    "link='https://www.booking.com/index.es.html'\n",
    "\n",
    "\n",
    "browser=start_up(dfolder=dfolder,link=link,geko_path=geko_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316802b",
   "metadata": {},
   "source": [
    "### 2. Accepting Cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "d07304fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clicked!'"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# click on \"Accept cookies\"\n",
    "x_path_cookies = '//button[@id=\"onetrust-accept-btn-handler\"]'\n",
    "check_and_click(browser, x_path_cookies, 'xpath')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408cdedb",
   "metadata": {},
   "source": [
    "### 3. Search Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "00244c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element(by='xpath',value='//div[@class=\"b9b84f4305\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f55ca",
   "metadata": {},
   "source": [
    "### 4. Input the place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "b494432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "place = input('Where do you want to go?')\n",
    "search1 = browser.find_element(by='xpath',value='//*[@id=\":re:\"]')\n",
    "search1.send_keys(place)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab55e89",
   "metadata": {},
   "source": [
    "### 5. Input the Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "8910628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "css_date='button.ebbedaf8ac:nth-child(2) > span:nth-child(1)'\n",
    "\n",
    "browser.find_element('css selector',css_date).click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "29ef65fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junio 2024\n"
     ]
    }
   ],
   "source": [
    "x_path_prev_date = '//button[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 f671049264 deab83296e f4552b6561 dc72a8413c c9804790f7\"]'\n",
    "while element_exists(browser, x_path_prev_date):\n",
    "        browser.find_element('xpath', x_path_prev_date).click()\n",
    "        time.sleep(1)\n",
    "x_path_month1 = '//h3[@class=\"e1eebb6a1e ee7ec6b631\"]'\n",
    "# Input the wanted year for the stay\n",
    "start_date = (input(\"Input the start date of your programmed stay in the form (XX mes XXXX). Use Spanish month names. ¡Cuidado con la ortografía!\")).lower()\n",
    "end_date = (input(\"Input the end date of your programmed stay in the form (XX mes XXXX). Use Spanish month names. ¡Cuidado con la ortografía!\")).lower()\n",
    "# Retrieve the current date\n",
    "month_and_year_start = start_date[3:]\n",
    "month_and_year_end = end_date[3:]\n",
    "month_and_year = browser.find_element('xpath', x_path_month1).text\n",
    "x_path_next_date = '//button[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 f671049264 deab83296e f4552b6561 dc72a8413c f073249358\"]'\n",
    "while month_and_year != month_and_year_start:\n",
    "        browser.find_element('xpath', x_path_next_date).click()\n",
    "        month_and_year = browser.find_element('xpath', x_path_month1).text\n",
    "        time.sleep(1)\n",
    "print(month_and_year)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203895c",
   "metadata": {},
   "source": [
    "### 6. Select the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "5b9f8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "months_dict = {'enero': '01', 'febrero': '02', 'marzo': '03', 'abril': '04', 'mayo': '05', 'junio': '06', 'julio': '07', 'agosto': '08', 'septiembre': '09', 'octubre': '10', 'noviembre': '11', 'diciembre': '12'}\n",
    "x_path_dates='//div[@id=\"calendar-searchboxdatepicker\"]//table[@class=\"eb03f3f27f\"]//tbody//td[@class=\"b80d5adb18\"]//span[@class=\"cf06f772fa\"]'\n",
    "dates = browser.find_elements('xpath',x_path_dates)\n",
    "from_day = start_date[:2]\n",
    "to_day = end_date[:2]\n",
    "month_start = month_and_year_start[:-5]\n",
    "month_end = month_and_year_end[:-5]\n",
    "year = month_and_year[-4:]\n",
    "for date in dates:\n",
    "    if date.get_attribute(\"data-date\") == f\"{year}-{months_dict[month_start]}-{from_day}\":\n",
    "        date.click()\n",
    "        break\n",
    "if month_start == month_end:\n",
    "    for date in dates:\n",
    "        if date.get_attribute(\"data-date\") == f\"{year}-{months_dict[month_end]}-{to_day}\":\n",
    "            date.click()\n",
    "            break\n",
    "else:\n",
    "    while browser.find_element('xpath', x_path_month1).text != month_and_year_end:\n",
    "        browser.find_element('xpath', x_path_next_date).click()\n",
    "    dates = browser.find_elements('xpath',x_path_dates)\n",
    "    for date in dates:\n",
    "        if date.get_attribute(\"data-date\") == f\"{year}-{months_dict[month_end]}-{to_day}\":\n",
    "            date.click()\n",
    "            break\n",
    "browser.find_element('css selector',css_date).click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb44508",
   "metadata": {},
   "source": [
    "### 7. Input the number of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "8af2effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path = '/html/body/div[3]/div[2]/div/form/div[1]/div[3]/div/button'\n",
    "\n",
    "browser.find_element('xpath', x_path).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "612cf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_people = int(input('How many people in total are you looking an accomodation for?'))\n",
    "\n",
    "css_minus = '/html/body/div[3]/div[2]/div/form/div[1]/div[3]/div/div/div/div/div[1]/div[2]/button[1]'\n",
    "css_plus = '/html/body/div[3]/div[2]/div/form/div[1]/div[3]/div/div/div/div/div[1]/div[2]/button[2]'\n",
    "if number_of_people == 1:\n",
    "    browser.find_element('xpath', css_minus).click()\n",
    "elif number_of_people > 2:\n",
    "    i = 2\n",
    "    while i < number_of_people:\n",
    "        browser.find_element('xpath', css_plus).click()\n",
    "        i+=1\n",
    "        time.sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37316444",
   "metadata": {},
   "source": [
    "### 8. Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_xpath='/html/body/div[3]/div[2]/div/form/div[1]/div[4]/button/span'\n",
    "\n",
    "check_obscures(browser,search_xpath , type='xpath')\n",
    "check_and_click(browser,search_xpath , type='xpath')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d0e1b",
   "metadata": {},
   "source": [
    "### 9. Extracting Number of Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "a586e86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_number_pages(browser):\n",
    "    '''\n",
    "    Get the number of pages. \n",
    "    '''\n",
    "    a = browser.find_elements('xpath',\n",
    "        '//button[@class=\"a83ed08757 a2028338ea\"]')\n",
    "    if a:\n",
    "        return(int(a[-1].text))\n",
    "    else:\n",
    "        return (1)\n",
    "\n",
    "pages = get_number_pages(browser)\n",
    "\n",
    "print(pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db15a4",
   "metadata": {},
   "source": [
    "### *4. Scrape date, room price, hotel name and hotel description. (5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c23443",
   "metadata": {},
   "source": [
    "### 10. Scraping Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "4423d27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 1\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n",
      "Page: 9\n",
      "Page: 10\n",
      "Page: 11\n",
      "Page: 12\n",
      "\n",
      "Done!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotels</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ilunion Aqua 4</td>\n",
       "      <td>8,1</td>\n",
       "      <td>€ 126</td>\n",
       "      <td>https://www.booking.com/hotel/es/confprtel-aqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel Olympia Universidades</td>\n",
       "      <td>8,4</td>\n",
       "      <td>€ 88</td>\n",
       "      <td>https://www.booking.com/hotel/es/universidades...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Silken Puerta Valencia</td>\n",
       "      <td>8,2</td>\n",
       "      <td>€ 125</td>\n",
       "      <td>https://www.booking.com/hotel/es/puertavalenci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Host &amp; Home</td>\n",
       "      <td>8,4</td>\n",
       "      <td>€ 103</td>\n",
       "      <td>https://www.booking.com/hotel/es/host-amp-home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ilunion Aqua 3</td>\n",
       "      <td>7,8</td>\n",
       "      <td>€ 119</td>\n",
       "      <td>https://www.booking.com/hotel/es/confortel-aqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Ilunion Valencia 3</td>\n",
       "      <td>7,7</td>\n",
       "      <td>€ 138</td>\n",
       "      <td>https://www.booking.com/hotel/es/confortel-val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>One Shot Mercat 09</td>\n",
       "      <td>8,3</td>\n",
       "      <td>€ 188</td>\n",
       "      <td>https://www.booking.com/hotel/es/one-shot-merc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>NH Valencia Las Ciencias</td>\n",
       "      <td>7,6</td>\n",
       "      <td>€ 157</td>\n",
       "      <td>https://www.booking.com/hotel/es/nh-valencia-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Barceló Valencia</td>\n",
       "      <td>8,5</td>\n",
       "      <td>€ 144</td>\n",
       "      <td>https://www.booking.com/hotel/es/barcelo-valen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Palau Apartments Valencia</td>\n",
       "      <td>9,0</td>\n",
       "      <td>€ 178</td>\n",
       "      <td>https://www.booking.com/hotel/es/palau-apartme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Hotels Ratings  Price  \\\n",
       "0                 Ilunion Aqua 4     8,1  € 126   \n",
       "1    Hotel Olympia Universidades     8,4   € 88   \n",
       "2         Silken Puerta Valencia     8,2  € 125   \n",
       "3                    Host & Home     8,4  € 103   \n",
       "4                 Ilunion Aqua 3     7,8  € 119   \n",
       "..                           ...     ...    ...   \n",
       "270           Ilunion Valencia 3     7,7  € 138   \n",
       "271           One Shot Mercat 09     8,3  € 188   \n",
       "272     NH Valencia Las Ciencias     7,6  € 157   \n",
       "273             Barceló Valencia     8,5  € 144   \n",
       "274    Palau Apartments Valencia     9,0  € 178   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://www.booking.com/hotel/es/confprtel-aqu...  \n",
       "1    https://www.booking.com/hotel/es/universidades...  \n",
       "2    https://www.booking.com/hotel/es/puertavalenci...  \n",
       "3    https://www.booking.com/hotel/es/host-amp-home...  \n",
       "4    https://www.booking.com/hotel/es/confortel-aqu...  \n",
       "..                                                 ...  \n",
       "270  https://www.booking.com/hotel/es/confortel-val...  \n",
       "271  https://www.booking.com/hotel/es/one-shot-merc...  \n",
       "272  https://www.booking.com/hotel/es/nh-valencia-l...  \n",
       "273  https://www.booking.com/hotel/es/barcelo-valen...  \n",
       "274  https://www.booking.com/hotel/es/palau-apartme...  \n",
       "\n",
       "[275 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pages = 5\n",
    "# Finding the button to change the page in Booking.com\n",
    "change_page_xpath = '/html/body/div[4]/div/div[2]/div/div[2]/div[3]/div[2]/div[2]/div[4]/div[2]/nav/nav/div/div[3]/button/span/span'\n",
    "css = 'div.b16a89683f:nth-child(3) > button:nth-child(1) > span:nth-child(1) > span:nth-child(1)'\n",
    "# Creating DataFrame\n",
    "data = pd.DataFrame(columns=['Hotels', 'Ratings', 'Price', 'Link'])\n",
    "# Make sure to be on the first page when starting to scrape the data\n",
    "first_page_xpath='/html/body/div[4]/div/div[2]/div/div[2]/div[3]/div[2]/div[2]/div[4]/div[2]/nav/nav/div/div[2]/ol/li[1]/button'\n",
    "check_and_click(browser,first_page_xpath , type='xpath')\n",
    "# loop to scrape the data and populate the DataFrame\n",
    "for i in range(pages):\n",
    "    print(f'Page: {i + 1}')\n",
    "    # Dividing the page in the Container Objects, one for every hotel\n",
    "    containers = browser.find_elements('xpath', '//div[@class=\"c066246e13\"]')\n",
    "    for hotel in containers:\n",
    "        hotel_name = hotel.find_element('xpath', './/div[@class=\"f6431b446c a15b38c233\"]').text\n",
    "        try:\n",
    "            hotel_rating = hotel.find_element('xpath', './/div[@class=\"a3b8729ab1 d86cee9b25\"]').text\n",
    "        except:\n",
    "            hotel_rating = np.nan\n",
    "        try:\n",
    "            hotel_price = hotel.find_element('xpath', './/span[@class=\"f6431b446c fbfd7c1165 e84eb96b1f\"]').text\n",
    "        except:\n",
    "            hotel_price = np.nan\n",
    "        try:\n",
    "            url = hotel.find_element('xpath', './/a[@href]')\n",
    "            hotel_url= url.get_attribute('href')\n",
    "        except:\n",
    "            hotel_url = np.nan\n",
    "        new_row = {'Hotels': hotel_name, 'Ratings': hotel_rating, 'Price':hotel_price, 'Link': hotel_url}\n",
    "        data = pd.concat([data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    # Change page with CSS Selector\n",
    "    next = browser.find_element('css selector', css)\n",
    "    time.sleep(2)\n",
    "print(\"\\nDone!\\n\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e9f2c",
   "metadata": {},
   "source": [
    "### 11. Scraping Descriptions using BeutifulSoup with parrallelized operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "2f6dc5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 50 links\n",
      "Scraped 100 links\n",
      "Scraped 150 links\n",
      "Scraped 200 links\n",
      "Scraped 250 links\n",
      "Scraped 275 links\n",
      "\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36'}\n",
    "\n",
    "# Function to scrape the descriptions using Beautiful Soup\n",
    "def scrape_description(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status() \n",
    "        # time.sleep(0.5)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    description_tag = soup.find('p', class_='a53cbfa6de b3efd73f69')\n",
    "\n",
    "    if description_tag:\n",
    "        return description_tag.get_text(strip=True)\n",
    "    else:\n",
    "        print(f\"Description tag not found on the page: {url}\")\n",
    "        return None\n",
    "\n",
    "# Set the number of concurrent threads (adjust this based on the processing power of your computer)\n",
    "num_threads = 16\n",
    "\n",
    "# Create a ThreadPoolExecutor to run operations in parallel\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Use executor.map to apply the scrape_description function to each URL in parallel\n",
    "    descriptions = []\n",
    "    for i, description in enumerate(executor.map(scrape_description, data['Link']), start=1):\n",
    "        descriptions.append(description)\n",
    "        # Print every 50 link to check the progess of the scraping\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Scraped {i} links\")\n",
    "\n",
    "# Assign the descriptions to the 'Descriptions' column in the DataFrame\n",
    "data['Descriptions'] = descriptions\n",
    "\n",
    "# Print count after all threads have completed\n",
    "print(f\"Scraped {len(descriptions)} links\")\n",
    "print(\"\\nDone!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "156a2b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotels</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Link</th>\n",
       "      <th>Descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ilunion Aqua 4</td>\n",
       "      <td>8,1</td>\n",
       "      <td>€ 126</td>\n",
       "      <td>https://www.booking.com/hotel/es/confprtel-aqu...</td>\n",
       "      <td>Este hotel de diseño está bien ubicado en Vale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel Olympia Universidades</td>\n",
       "      <td>8,4</td>\n",
       "      <td>€ 88</td>\n",
       "      <td>https://www.booking.com/hotel/es/universidades...</td>\n",
       "      <td>El Hotel Olympia Universidades ofrece habitaci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Silken Puerta Valencia</td>\n",
       "      <td>8,2</td>\n",
       "      <td>€ 125</td>\n",
       "      <td>https://www.booking.com/hotel/es/puertavalenci...</td>\n",
       "      <td>El Silken Puerta Valencia se encuentra a 5 min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Host &amp; Home</td>\n",
       "      <td>8,4</td>\n",
       "      <td>€ 103</td>\n",
       "      <td>https://www.booking.com/hotel/es/host-amp-home...</td>\n",
       "      <td>Host &amp; Home está muy bien situado en el barrio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ilunion Aqua 3</td>\n",
       "      <td>7,8</td>\n",
       "      <td>€ 119</td>\n",
       "      <td>https://www.booking.com/hotel/es/confortel-aqu...</td>\n",
       "      <td>El hotel de diseño Ilunion Aqua 3 está situado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Ilunion Valencia 3</td>\n",
       "      <td>7,7</td>\n",
       "      <td>€ 138</td>\n",
       "      <td>https://www.booking.com/hotel/es/confortel-val...</td>\n",
       "      <td>El Ilunion Valencia 3 cuenta con piscina al ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>One Shot Mercat 09</td>\n",
       "      <td>8,3</td>\n",
       "      <td>€ 188</td>\n",
       "      <td>https://www.booking.com/hotel/es/one-shot-merc...</td>\n",
       "      <td>El One Shot Mercat 09, situado en el barrio de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>NH Valencia Las Ciencias</td>\n",
       "      <td>7,6</td>\n",
       "      <td>€ 157</td>\n",
       "      <td>https://www.booking.com/hotel/es/nh-valencia-l...</td>\n",
       "      <td>Este hotel goza de una ubicación idónea junto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Barceló Valencia</td>\n",
       "      <td>8,5</td>\n",
       "      <td>€ 144</td>\n",
       "      <td>https://www.booking.com/hotel/es/barcelo-valen...</td>\n",
       "      <td>El elegante Barceló Valencia está situado junt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Palau Apartments Valencia</td>\n",
       "      <td>9,0</td>\n",
       "      <td>€ 178</td>\n",
       "      <td>https://www.booking.com/hotel/es/palau-apartme...</td>\n",
       "      <td>Palau Apartments Valencia cuenta con vistas a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Hotels Ratings  Price  \\\n",
       "0                 Ilunion Aqua 4     8,1  € 126   \n",
       "1    Hotel Olympia Universidades     8,4   € 88   \n",
       "2         Silken Puerta Valencia     8,2  € 125   \n",
       "3                    Host & Home     8,4  € 103   \n",
       "4                 Ilunion Aqua 3     7,8  € 119   \n",
       "..                           ...     ...    ...   \n",
       "270           Ilunion Valencia 3     7,7  € 138   \n",
       "271           One Shot Mercat 09     8,3  € 188   \n",
       "272     NH Valencia Las Ciencias     7,6  € 157   \n",
       "273             Barceló Valencia     8,5  € 144   \n",
       "274    Palau Apartments Valencia     9,0  € 178   \n",
       "\n",
       "                                                  Link  \\\n",
       "0    https://www.booking.com/hotel/es/confprtel-aqu...   \n",
       "1    https://www.booking.com/hotel/es/universidades...   \n",
       "2    https://www.booking.com/hotel/es/puertavalenci...   \n",
       "3    https://www.booking.com/hotel/es/host-amp-home...   \n",
       "4    https://www.booking.com/hotel/es/confortel-aqu...   \n",
       "..                                                 ...   \n",
       "270  https://www.booking.com/hotel/es/confortel-val...   \n",
       "271  https://www.booking.com/hotel/es/one-shot-merc...   \n",
       "272  https://www.booking.com/hotel/es/nh-valencia-l...   \n",
       "273  https://www.booking.com/hotel/es/barcelo-valen...   \n",
       "274  https://www.booking.com/hotel/es/palau-apartme...   \n",
       "\n",
       "                                          Descriptions  \n",
       "0    Este hotel de diseño está bien ubicado en Vale...  \n",
       "1    El Hotel Olympia Universidades ofrece habitaci...  \n",
       "2    El Silken Puerta Valencia se encuentra a 5 min...  \n",
       "3    Host & Home está muy bien situado en el barrio...  \n",
       "4    El hotel de diseño Ilunion Aqua 3 está situado...  \n",
       "..                                                 ...  \n",
       "270  El Ilunion Valencia 3 cuenta con piscina al ai...  \n",
       "271  El One Shot Mercat 09, situado en el barrio de...  \n",
       "272  Este hotel goza de una ubicación idónea junto ...  \n",
       "273  El elegante Barceló Valencia está situado junt...  \n",
       "274  Palau Apartments Valencia cuenta con vistas a ...  \n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb62350",
   "metadata": {},
   "source": [
    "### 12. Order by Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "075609b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean and convert the 'Price' column to numeric values\n",
    "# data['Price'] = pd.to_numeric(data['Price'].str.replace('€', '').str.replace('.', ''), errors='coerce')\n",
    "\n",
    "# # Sort the DataFrame by the 'Price' column in ascending order\n",
    "# data_sorted = data.sort_values(by='Price', ascending=False)\n",
    "# display(data_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf1b9a2",
   "metadata": {},
   "source": [
    "### 13. Create CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "24df9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_name = 'Madrid.csv'\n",
    "#csv = data.to_csv(f'.\\{csv_name}', sep=',')\n",
    "#csv = data.to_csv('Madrid', sep=',')\n",
    "data.to_csv('../Webscrapping_Booking.Com-1/robustness_check/Valencia_Data_21_22.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('pyannote')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e5bc56a5e59828724b9606669ef2e877f786cc96978258679ba8b9f5956bc86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
